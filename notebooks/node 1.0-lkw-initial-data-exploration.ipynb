{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separate out experiments from one file that contains multiple experiments**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "exp_no = 104\n",
    "last_file_no = 152\n",
    "file_name = str(exp_no)+\"_SHT_SMD.txt\"\n",
    "\n",
    "file_path = \"../data/01_raw/\" + file_name\n",
    "# print(file_path)\n",
    "df = pd.read_csv(file_path, sep=',' , usecols=['timestamp','SHT40_temp','SHT40_Humidity','A1_Sensor', 'A1_Resistance'])\n",
    "timestamp_data = df['timestamp'].values \n",
    "sht40_temp_data = df['SHT40_temp'].values\n",
    "sht40_humidity_data = df['SHT40_Humidity'].values \n",
    "a1_sensor_data = df['A1_Sensor'].values \n",
    "a1_r_data = df['A1_Resistance'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find peaks and their properties\n",
    "peaks, properties = find_peaks(a1_sensor_data, width=50, height=1)\n",
    "\n",
    "# Get the peak heights\n",
    "peak_heights = properties['peak_heights']\n",
    "\n",
    "# Initialize lists to hold the smaller and larger peaks\n",
    "smaller_peaks = []\n",
    "larger_peaks = []\n",
    "\n",
    "# Iterate over the peaks\n",
    "for i in range(len(peaks) - 1):\n",
    "    # If the next peak is smaller, label the current peak as a larger peak\n",
    "    if peak_heights[i] > peak_heights[i + 1]:\n",
    "        larger_peaks.append(peaks[i])\n",
    "        smaller_peaks.append(peaks[i + 1])\n",
    "\n",
    "# Convert lists to numpy arrays for indexing\n",
    "smaller_peaks = np.array(smaller_peaks)\n",
    "larger_peaks = np.array(larger_peaks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mm/nclx10yn5lnb99y4352wnw6w0000gn/T/ipykernel_3613/3124727400.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_stacked = pd.concat([df_stacked, df_labelled])\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the smaller_peaks array\n",
    "# create a df to store the data\n",
    "# timestamp,SHT40_temp,SHT40_Humidity,A1_Sensor,A1_Resistance\n",
    "df_stacked = pd.DataFrame(columns=['exp_no', 'timestamp', 'SHT40_temp', 'SHT40_Humidity', 'A1_Sensor', 'A1_Resistance'])\n",
    "\n",
    "for i in range(len(smaller_peaks) - 1):\n",
    "    # Get the data of between the current and next smaller peak\n",
    "    data_c = sht40_temp_data[smaller_peaks[i]:smaller_peaks[i + 1]]\n",
    "    data_rh = sht40_humidity_data[smaller_peaks[i]:smaller_peaks[i + 1]]\n",
    "    data_v = a1_sensor_data[smaller_peaks[i]:smaller_peaks[i + 1]]\n",
    "    data_r = a1_r_data[smaller_peaks[i]:smaller_peaks[i + 1]]\n",
    "    \n",
    "    timestamps = timestamp_data[smaller_peaks[i]:smaller_peaks[i + 1]]\n",
    "    relative_time = timestamps - timestamps[0]\n",
    "    # create a new header called experiment number with each iteration being 1 experiment and add it to the data\n",
    "    exp_no = pd.Series(i, index=range(len(data_r)))\n",
    "    # create a new df with the data\n",
    "    df_labelled = pd.DataFrame({'exp_no': exp_no, 'timestamp': relative_time, 'SHT40_temp': data_c, 'SHT40_Humidity': data_rh, 'A1_Sensor': data_v, 'A1_Resistance': data_r})\n",
    "    # concat each df_labelled to the df_stacked\n",
    "    df_stacked = pd.concat([df_stacked, df_labelled])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "exp_no = 104\n",
    "file_name = f\"{exp_no}_SHT_SMD.txt\"\n",
    "file_path = f\"../data/01_raw/{file_name}\"\n",
    "\n",
    "# Read data\n",
    "df = pd.read_csv(file_path, sep=',', usecols=['timestamp', 'SHT40_temp', 'SHT40_Humidity', 'A1_Sensor', 'A1_Resistance'])\n",
    "\n",
    "# Find peaks\n",
    "peaks, properties = find_peaks(df['A1_Sensor'], width=50, height=1)\n",
    "peak_heights = properties['peak_heights']\n",
    "\n",
    "# Determine smaller and larger peaks\n",
    "smaller_peaks, larger_peaks = [], []\n",
    "for i in range(len(peaks) - 1):\n",
    "    if peak_heights[i] > peak_heights[i + 1]:\n",
    "        larger_peaks.append(peaks[i])\n",
    "        smaller_peaks.append(peaks[i + 1])\n",
    "\n",
    "# Process data\n",
    "df_stacked_list = []\n",
    "for i in range(len(smaller_peaks) - 1):\n",
    "    df_subset = df.iloc[smaller_peaks[i]:smaller_peaks[i + 1]].copy()\n",
    "    df_subset['exp_no'] = i\n",
    "    df_subset['timestamp'] -= df_subset['timestamp'].iloc[0]\n",
    "    df_stacked_list.append(df_subset)\n",
    "\n",
    "df_stacked = pd.concat(df_stacked_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stacked.head()\n",
    "# write df_stacked to csv\n",
    "df_stacked.to_csv(f\"../data/02_intermediate/{exp_no}_stacked.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kedro-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
