{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The kedro.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext kedro.ipython\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import yaml\n",
    "\n",
    "from typing import Dict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "%load_ext kedro.ipython\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/23/24 15:32:59] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Resolved project path as:                                              <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#139\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/Users/gavinlou/Developer/kedro/ML-GS/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">gas-sensor-ml.</span>                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To set a different path, run <span style=\"color: #008000; text-decoration-color: #008000\">'%reload_kedro &lt;project_root&gt;'</span>            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/23/24 15:32:59]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Resolved project path as:                                              \u001b]8;id=946376;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=920916;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#139\u001b\\\u001b[2m139\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[35m/Users/gavinlou/Developer/kedro/ML-GS/\u001b[0m\u001b[95mgas-sensor-ml.\u001b[0m                   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To set a different path, run \u001b[32m'%reload_kedro \u001b[0m\u001b[32m<\u001b[0m\u001b[32mproject_root\u001b[0m\u001b[32m>\u001b[0m\u001b[32m'\u001b[0m            \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/23/24 15:32:59] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Kedro project gas-sensor-ml                                            <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#108\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/23/24 15:32:59]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Kedro project gas-sensor-ml                                            \u001b]8;id=186800;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=418529;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#108\u001b\\\u001b[2m108\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Defined global variable <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'session'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'catalog'</span> and            <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#109\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'pipelines'</span>                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Defined global variable \u001b[32m'context'\u001b[0m, \u001b[32m'session'\u001b[0m, \u001b[32m'catalog'\u001b[0m and            \u001b]8;id=576529;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=546373;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#109\u001b\\\u001b[2m109\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m'pipelines'\u001b[0m                                                            \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Registered line magic <span style=\"color: #008000; text-decoration-color: #008000\">'run_viz'</span>                                        <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#115\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Registered line magic \u001b[32m'run_viz'\u001b[0m                                        \u001b]8;id=228309;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=257491;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#115\u001b\\\u001b[2m115\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext kedro.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/23/24 15:33:03] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'mox_bin'</span> <span style=\"font-weight: bold\">(</span>ParquetDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                    <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/23/24 15:33:03]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'mox_bin'\u001b[0m \u001b[1m(\u001b[0mParquetDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                    \u001b]8;id=477686;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=126594;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'params:complete_lstm_model.model_options'</span>       <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">(</span>MemoryDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'params:complete_lstm_model.model_options'\u001b[0m       \u001b]8;id=373832;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=103313;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m(\u001b[0mMemoryDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                                                 \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'model_input_table'</span> <span style=\"font-weight: bold\">(</span>ParquetDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>          <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'model_input_table'\u001b[0m \u001b[1m(\u001b[0mParquetDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m          \u001b]8;id=472873;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=905032;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mox_bin = catalog.load(\"mox_bin\")\n",
    "# mox_bin.tail()\n",
    "lstm_params = catalog.load(\"params:complete_lstm_model.model_options\")\n",
    "study_params = catalog.load(\"params:complete_lstm_model.study_options\")\n",
    "model_input_table = catalog.load(\"model_input_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_classes': 1, 'num_epochs': 10, 'batch_size': 32, 'learning_rate': 0.001, 'test_size': 0.2, 'random_state': 3, 'input_size': 1, 'sequence_length': 1500, 'hidden_size': 128, 'num_layers': 2, 'val_size': 0.2}\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(lstm_params)\n",
    "print(lstm_params['num_epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyper-parameters \n",
    "\n",
    "num_classes = lstm_params['num_classes']\n",
    "num_epochs = lstm_params['num_epochs']\n",
    "batch_size = lstm_params['batch_size']\n",
    "learning_rate = lstm_params['learning_rate']\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Each feature as a time step in your sequence, you could set sequence_length to 150 and input_size to 1.\n",
    "This would mean you are feeding in sequences of length 150, with each time step in the sequence having 1 feature.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "input_size = lstm_params['input_size']\n",
    "sequence_length = lstm_params['sequence_length'] # the window it trains with can be selected\n",
    "hidden_size = lstm_params['hidden_size']\n",
    "num_layers = lstm_params['num_layers']\n",
    "random_state = lstm_params['random_state']\n",
    "\n",
    "# batch_size = lstm_params['batch_size']  # You can adjust the batch size according to your needs\n",
    "\n",
    "test_size = lstm_params['test_size']\n",
    "val_size = lstm_params['val_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN processing\n",
    "# forward fill NaN values\n",
    "def _ffill_NaN (X_dataset: np.ndarray) -> np.ndarray:\n",
    "    X_dataset_df = pd.DataFrame(X_dataset)\n",
    "    X_dataset_df.ffill(inplace=True)\n",
    "    # Convert back to numpy arrays\n",
    "    return X_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "bin_0        \u001b[1;36m0\u001b[0m\n",
       "bin_1        \u001b[1;36m0\u001b[0m\n",
       "bin_2        \u001b[1;36m0\u001b[0m\n",
       "bin_3        \u001b[1;36m0\u001b[0m\n",
       "bin_4        \u001b[1;36m0\u001b[0m\n",
       "            ..\n",
       "bin_1496     \u001b[1;36m0\u001b[0m\n",
       "bin_1497     \u001b[1;36m0\u001b[0m\n",
       "bin_1498     \u001b[1;36m0\u001b[0m\n",
       "bin_1499     \u001b[1;36m0\u001b[0m\n",
       "res_ratio    \u001b[1;36m0\u001b[0m\n",
       "Length: \u001b[1;36m1501\u001b[0m, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean NaN values from input table\n",
    "_ffill_NaN(model_input_table)\n",
    "# check for NaN values\n",
    "model_input_table.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement LSTM functions below\n",
    "# there is no validation set in this example\n",
    "# load mox_table as input\n",
    "\n",
    "def split_data(model_input_table: pd.DataFrame) -> torch.tensor:\n",
    "    # Split data into features and target\n",
    "    X = model_input_table[model_input_table.columns[:-1]].values  # Assuming last column is the target\n",
    "    y = model_input_table[model_input_table.columns[-1]].values\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size = test_size, random_state = random_state)\n",
    "    \n",
    "    # Further split to create a validation set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, \n",
    "        test_size = val_size, \n",
    "        random_state = random_state)\n",
    "    \n",
    "    # Initialize StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    # Fit on training data\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Transform both training and testing data\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Ensure y_train and y_test are in the correct format\n",
    "    if isinstance(y_train, pd.Series):\n",
    "        y_train = y_train.values\n",
    "    if isinstance(y_val, pd.Series):\n",
    "        y_val = y_val.values\n",
    "    if isinstance(y_test, pd.Series):\n",
    "        y_test = y_test.values\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train_scaled.astype(np.float32))\n",
    "    y_train_tensor = torch.tensor(y_train.astype(np.float32))\n",
    "\n",
    "    X_val_tensor = torch.tensor(X_val_scaled.astype(np.float32))\n",
    "    y_val_tensor = torch.tensor(y_val.astype(np.float32))\n",
    "\n",
    "    X_test_tensor = torch.tensor(X_test_scaled.astype(np.float32))\n",
    "    y_test_tensor = torch.tensor(y_test.astype(np.float32))\n",
    "\n",
    "    return X_train_tensor, X_val_tensor, X_test_tensor, y_train_tensor, y_val_tensor, y_test_tensor\n",
    "\n",
    "\n",
    "# create X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor from split_data(df)\n",
    "X_train_tensor, X_val_tensor, X_test_tensor, y_train_tensor, y_val_tensor, y_test_tensor = split_data(model_input_table)\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "# Initialize DataLoaders\n",
    "# batch_size = lstm_params['batch_size']  # You can adjust the batch size according to your needs\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTUNA model\n",
    "\n",
    "# Optuna managed model\n",
    "class RNN(nn.Module):\n",
    "    # def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "    def __init__(self, trial, input_size, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        # Optuna suggests the number of layers and hidden size\n",
    "        self.num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "        self.hidden_size = trial.suggest_int(\"hidden_size\", 30, 100)\n",
    "\n",
    "        # Optuna suggests the dropout ratio of each layer\n",
    "        dropout_rate = trial.suggest_float(\"dropout_rate\", 0, 0.5)\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, \n",
    "            self.hidden_size, \n",
    "            self.num_layers, \n",
    "            batch_first=True,\n",
    "            dropout=(dropout_rate if self.num_layers > 1 else 0), \n",
    "            )\n",
    "        self.fc = nn.Linear(self.hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        out, _ = self.lstm(x, (h0,c0))  \n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "def define_model(trial, input_size, num_classes):\n",
    "    model = RNN(trial, input_size, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna managed training\n",
    "def objective(trial, input_size, num_classes):\n",
    "    model = define_model(trial, input_size, num_classes).to(device)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(torch.optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training of the model\n",
    "    n_total_steps = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for i, (bins, target) in enumerate(train_loader):\n",
    "            bins = bins.reshape(-1, sequence_length, input_size).to(device)\n",
    "            target = target.squeeze().to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(bins)\n",
    "            # Example of reshaping/squeezing if applicable\n",
    "            outputs = outputs.squeeze()  # Removes dimensions of size 1\n",
    "            # outputs = outputs[:64]  # Adjust if you need to slice the outputs\n",
    "            # target = target.squeeze().to(device)  # Add an extra dimension to match outputs\n",
    "            loss = criterion(outputs, target)\n",
    "        \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():  # Don't calculate gradients\n",
    "            total_loss = 0\n",
    "            count = 0\n",
    "\n",
    "            for bins, target in test_loader:  # Replace with your validation loader\n",
    "                bins = bins.reshape(-1, sequence_length, input_size).to(device)\n",
    "                target = target.squeeze().to(device)  # Add an extra dimension to match outputs\n",
    "                \n",
    "                outputs = model(bins)\n",
    "                outputs = outputs.squeeze()\n",
    "\n",
    "                loss = criterion(outputs, target)\n",
    "                total_loss += loss.item()\n",
    "                count += 1\n",
    "        \n",
    "        model.train() # Set the model back to training mode\n",
    "\n",
    "        rmse = np.sqrt(total_loss / count)\n",
    "        trial.report(rmse, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "    return rmse\n",
    "            # print(f'Epoch [{epoch+1}/{num_epochs}], RMSE on validation data: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-24 15:34:24,876] A new study created in memory with name: no-name-fc4797e9-8210-4801-8a7f-83f7fbca92a0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-24 15:38:53,993] Trial 0 finished with value: 0.08793570348750154 and parameters: {'num_layers': 3, 'hidden_size': 74, 'dropout_rate': 0.42405752634736116, 'optimizer': 'Adam', 'lr': 0.0029712251186688977}. Best is trial 0 with value: 0.08793570348750154.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  1\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  1\n",
      "Best trial:\n",
      "  Value:  0.08793570348750154\n",
      "  Params: \n",
      "    num_layers: 3\n",
      "    hidden_size: 74\n",
      "    dropout_rate: 0.42405752634736116\n",
      "    optimizer: Adam\n",
      "    lr: 0.0029712251186688977\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    # study.optimize(objective, n_trials=5, timeout=600)\n",
    "    study.optimize(lambda trial: objective(trial, input_size, num_classes), n_trials=1, timeout=600)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kedro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
