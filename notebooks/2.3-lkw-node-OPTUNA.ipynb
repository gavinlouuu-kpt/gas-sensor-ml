{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The kedro.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext kedro.ipython\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import yaml\n",
    "\n",
    "from typing import Dict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "%load_ext kedro.ipython\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/23/24 15:06:00] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'mox_bin'</span> <span style=\"font-weight: bold\">(</span>ParquetDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                    <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/23/24 15:06:00]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'mox_bin'\u001b[0m \u001b[1m(\u001b[0mParquetDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                    \u001b]8;id=775350;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=378917;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/23/24 15:06:01] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'params:complete_lstm_model.model_options'</span>       <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">(</span>MemoryDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/23/24 15:06:01]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'params:complete_lstm_model.model_options'\u001b[0m       \u001b]8;id=140748;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=953962;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m(\u001b[0mMemoryDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m                                                 \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'model_input_table'</span> <span style=\"font-weight: bold\">(</span>ParquetDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>          <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py#502\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">502</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'model_input_table'\u001b[0m \u001b[1m(\u001b[0mParquetDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m          \u001b]8;id=874227;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=210066;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py#502\u001b\\\u001b[2m502\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mox_bin = catalog.load(\"mox_bin\")\n",
    "# mox_bin.tail()\n",
    "lstm_params = catalog.load(\"params:complete_lstm_model.model_options\")\n",
    "model_input_table = catalog.load(\"model_input_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_classes': 1, 'num_epochs': 100, 'batch_size': 32, 'learning_rate': 0.001, 'test_size': 0.2, 'random_state': 3, 'input_size': 1, 'sequence_length': 1500, 'hidden_size': 128, 'num_layers': 4, 'val_size': 0.2}\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(lstm_params)\n",
    "print(lstm_params['num_epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyper-parameters \n",
    "\n",
    "num_classes = lstm_params['num_classes']\n",
    "num_epochs = lstm_params['num_epochs']\n",
    "batch_size = lstm_params['batch_size']\n",
    "learning_rate = lstm_params['learning_rate']\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Each feature as a time step in your sequence, you could set sequence_length to 150 and input_size to 1.\n",
    "This would mean you are feeding in sequences of length 150, with each time step in the sequence having 1 feature.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "input_size = lstm_params['input_size']\n",
    "sequence_length = lstm_params['sequence_length'] # the window it trains with can be selected\n",
    "hidden_size = lstm_params['hidden_size']\n",
    "num_layers = lstm_params['num_layers']\n",
    "random_state = lstm_params['random_state']\n",
    "\n",
    "# batch_size = lstm_params['batch_size']  # You can adjust the batch size according to your needs\n",
    "\n",
    "test_size = lstm_params['test_size']\n",
    "val_size = lstm_params['val_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN processing\n",
    "# forward fill NaN values\n",
    "def _ffill_NaN (X_dataset: np.ndarray) -> np.ndarray:\n",
    "    X_dataset_df = pd.DataFrame(X_dataset)\n",
    "    # Fill NaN values with the mean of the column\n",
    "    X_dataset_df.ffill(inplace=True)\n",
    "    # Convert back to numpy arrays\n",
    "    return X_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement LSTM functions below\n",
    "# there is no validation set in this example\n",
    "# load mox_table as input\n",
    "\n",
    "def split_data(model_input_table: pd.DataFrame) -> torch.tensor:\n",
    "    # Split data into features and target\n",
    "    X = model_input_table[model_input_table.columns[:-1]].values  # Assuming last column is the target\n",
    "    y = model_input_table[model_input_table.columns[-1]].values\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size = test_size, random_state = random_state)\n",
    "    \n",
    "    # Further split to create a validation set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, \n",
    "        test_size = val_size, random_state = random_state)\n",
    "    \n",
    "    # Clean NaN values\n",
    "    X_train = _ffill_NaN(X_train)\n",
    "    X_val = _ffill_NaN(X_val)\n",
    "    X_test = _ffill_NaN(X_test)\n",
    "\n",
    "    X_val_df = pd.DataFrame(X_val, columns=model_input_table.columns[:-1])\n",
    "    # Fill NaN values with the mean of the column\n",
    "    X_val_df.fillna(X_val_df.mean(), inplace=True)\n",
    "    # Convert back to numpy arrays\n",
    "    X_val = X_val_df.values\n",
    "\n",
    "    # Initialize StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    # Fit on training data\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Transform both training and testing data\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Ensure y_train and y_test are in the correct format\n",
    "    if isinstance(y_train, pd.Series):\n",
    "        y_train = y_train.values\n",
    "    if isinstance(y_val, pd.Series):\n",
    "        y_val = y_val.values\n",
    "    if isinstance(y_test, pd.Series):\n",
    "        y_test = y_test.values\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train_scaled.astype(np.float32))\n",
    "    y_train_tensor = torch.tensor(y_train.astype(np.float32))\n",
    "\n",
    "    X_val_tensor = torch.tensor(X_val_scaled.astype(np.float32))\n",
    "    y_val_tensor = torch.tensor(y_val.astype(np.float32))\n",
    "\n",
    "    X_test_tensor = torch.tensor(X_test_scaled.astype(np.float32))\n",
    "    y_test_tensor = torch.tensor(y_test.astype(np.float32))\n",
    "\n",
    "    return X_train_tensor, X_val_tensor, X_test_tensor, y_train_tensor, y_val_tensor, y_test_tensor\n",
    "\n",
    "\n",
    "# create X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor from split_data(df)\n",
    "X_train_tensor, X_val_tensor, X_test_tensor, y_train_tensor, y_val_tensor, y_test_tensor = split_data(model_input_table)\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "# Initialize DataLoaders\n",
    "# batch_size = lstm_params['batch_size']  # You can adjust the batch size according to your needs\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTUNA model\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class RNN(nn.Module):\n",
    "    # def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "    def __init__(self, trial, input_size, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        # Optuna suggests the number of layers and hidden size\n",
    "        self.num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "        self.hidden_size = trial.suggest_int(\"hidden_size\", 30, 100)\n",
    "\n",
    "        # Optuna suggests the dropout ratio of each layer\n",
    "        dropout_rate = trial.suggest_float(\"dropout_rate\", 0, 0.5)\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, \n",
    "            self.hidden_size, \n",
    "            self.num_layers, \n",
    "            batch_first=True,\n",
    "            dropout=(dropout_rate if self.num_layers > 1 else 0), \n",
    "            )\n",
    "        self.fc = nn.Linear(self.hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        out, _ = self.lstm(x, (h0,c0))  \n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "def define_model(trial, input_size, num_classes):\n",
    "    model = RNN(trial, input_size, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna managed training\n",
    "def objective(trial):\n",
    "    model = define_model(trial, input_size, num_classes).to(device)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(torch.optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training of the model\n",
    "    n_total_steps = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for i, (bins, target) in enumerate(train_loader):\n",
    "            bins = bins.reshape(-1, sequence_length, input_size).to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(bins)\n",
    "            # Example of reshaping/squeezing if applicable\n",
    "            outputs = outputs.squeeze()  # Removes dimensions of size 1\n",
    "            outputs = outputs[:64]  # Adjust if you need to slice the outputs\n",
    "\n",
    "            target = target.unsqueeze(1).to(device)  # Add an extra dimension to match outputs\n",
    "            loss = criterion(outputs, target)\n",
    "        \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():  # Don't calculate gradients\n",
    "            total_loss = 0\n",
    "            count = 0\n",
    "\n",
    "            for bins, target in test_loader:  # Replace with your validation loader\n",
    "                bins = bins.reshape(-1, sequence_length, input_size).to(device)\n",
    "                target = target.unsqueeze(1).to(device)  # Add an extra dimension to match outputs\n",
    "                outputs = model(bins)\n",
    "                loss = criterion(outputs, target)\n",
    "                total_loss += loss.item()\n",
    "                count += 1\n",
    "        \n",
    "        model.train() # Set the model back to training mode\n",
    "\n",
    "        rmse = np.sqrt(total_loss / count)\n",
    "        trial.report(rmse, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "    return rmse\n",
    "            # print(f'Epoch [{epoch+1}/{num_epochs}], RMSE on validation data: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-23 15:19:52,674] A new study created in memory with name: no-name-3f0a3ee6-3293-4b19-8c7d-6c702e8e90f1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/23/24 15:19:54] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> <span style=\"color: #800080; text-decoration-color: #800080\">/Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site</span> <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/lib/python3.10/warnings.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/lib/python3.10/warnings.py#109\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">-packages/torch/nn/modules/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">loss.py</span>:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">535</span>: UserWarning: Using a target    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         size <span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]))</span> that is different to the input size         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span><span style=\"font-weight: bold\">]))</span>. This will likely lead to incorrect results due to  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         broadcasting. Please ensure they have the same size.                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">F.mse_loss</span><span style=\"font-weight: bold\">(</span>input, target, <span style=\"color: #808000; text-decoration-color: #808000\">reduction</span>=<span style=\"color: #800080; text-decoration-color: #800080\">self</span>.reduction<span style=\"font-weight: bold\">)</span>           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/23/24 15:19:54]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m \u001b[35m/Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site\u001b[0m \u001b]8;id=175617;file:///Users/gavinlou/.pyenv/versions/3.10.13/lib/python3.10/warnings.py\u001b\\\u001b[2mwarnings.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=803845;file:///Users/gavinlou/.pyenv/versions/3.10.13/lib/python3.10/warnings.py#109\u001b\\\u001b[2m109\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[35m-packages/torch/nn/modules/\u001b[0m\u001b[95mloss.py\u001b[0m:\u001b[1;36m535\u001b[0m: UserWarning: Using a target    \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         size \u001b[1m(\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m that is different to the input size         \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m(\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m. This will likely lead to incorrect results due to  \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         broadcasting. Please ensure they have the same size.                   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           return \u001b[1;35mF.mse_loss\u001b[0m\u001b[1m(\u001b[0minput, target, \u001b[33mreduction\u001b[0m=\u001b[35mself\u001b[0m.reduction\u001b[1m)\u001b[0m           \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/23/24 15:20:17] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> <span style=\"color: #800080; text-decoration-color: #800080\">/Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site</span> <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/lib/python3.10/warnings.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/lib/python3.10/warnings.py#109\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">-packages/torch/nn/modules/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">loss.py</span>:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">535</span>: UserWarning: Using a target    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         size <span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]))</span> that is different to the input size          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"font-weight: bold\">]))</span>. This will likely lead to incorrect results due to   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         broadcasting. Please ensure they have the same size.                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>           return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">F.mse_loss</span><span style=\"font-weight: bold\">(</span>input, target, <span style=\"color: #808000; text-decoration-color: #808000\">reduction</span>=<span style=\"color: #800080; text-decoration-color: #800080\">self</span>.reduction<span style=\"font-weight: bold\">)</span>           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/23/24 15:20:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m \u001b[35m/Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site\u001b[0m \u001b]8;id=6900;file:///Users/gavinlou/.pyenv/versions/3.10.13/lib/python3.10/warnings.py\u001b\\\u001b[2mwarnings.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=341949;file:///Users/gavinlou/.pyenv/versions/3.10.13/lib/python3.10/warnings.py#109\u001b\\\u001b[2m109\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[35m-packages/torch/nn/modules/\u001b[0m\u001b[95mloss.py\u001b[0m:\u001b[1;36m535\u001b[0m: UserWarning: Using a target    \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         size \u001b[1m(\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m7\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m that is different to the input size          \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m(\u001b[0m\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m. This will likely lead to incorrect results due to   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         broadcasting. Please ensure they have the same size.                   \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m           return \u001b[1;35mF.mse_loss\u001b[0m\u001b[1m(\u001b[0minput, target, \u001b[33mreduction\u001b[0m=\u001b[35mself\u001b[0m.reduction\u001b[1m)\u001b[0m           \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kedro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
